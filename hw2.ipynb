{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Anak Agung Ngurah Bagus Trihatmaja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6.1\n",
    "\n",
    "> Write a code in Python whose input is a training dataset {(x1, y1), . . . , (xN , yN )} and its output is the weight vector θ in the linear regression model y = θ'φ(x), for a given nonlinear mapping φ(·). Implement two cases: i) using the closed-form solution, ii) using a stochastic gradient descent on mini-batches of size m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import scipy.io\n",
    "import math\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function generates data based on the formula we input \n",
    "# For this time we will generate a square function added with a noise\n",
    "f = lambda  x: x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closed function regression\n",
    "def closed_function_regression(train_X, train_Y):\n",
    "  X = np.array(train_X)\n",
    "  y = np.array(train_Y)\n",
    "  \n",
    "  \n",
    "  # TODO: Check again here  \n",
    "  # ones = np.ones(len(X))\n",
    "  # X = np.column_stack((ones, X))\n",
    "  y = np.array(y)\n",
    "        \n",
    "  Xt = transpose(X)\n",
    "  product = dot(Xt, X)\n",
    "  theInverse = inv(product)\n",
    "  w = dot(dot(theInverse, Xt), y)\n",
    "        \n",
    "  return w       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(train_X, train_Y, batch_size):\n",
    "    X = train_X\n",
    "    y = train_Y\n",
    "    \n",
    "    random_indices = np.random.choice(len(X), len(y), replace=False)\n",
    "    \n",
    "    X_shuffled = X[random_indices,:]\n",
    "    y_shuffled = y[random_indices]\n",
    "    mini_batches = [(X_shuffled[i:i+batch_size,:], y_shuffled[i:i+batch_size]) for\n",
    "                   i in range(0, len(y), batch_size)]\n",
    "    return mini_batches\n",
    "    \n",
    "\n",
    "def mini_gradient_descent(train_X, train_Y, learning_rate, num_iter, batch_size):\n",
    "    # Prepare the data\n",
    "    X = np.array(train_X)\n",
    "    y = np.array(train_Y)\n",
    "    \n",
    "    # TODO: Check why do we need to put 1 here\n",
    "    # ones = np.ones(len(X))\n",
    "    # X = np.column_stack((ones, X))\n",
    "    # y = np.array(y)\n",
    "    \n",
    "    # Randomize the data and split into samples\n",
    "    df = shuffle_data(X, y, batch_size)\n",
    "    \n",
    "    # Get the dimension\n",
    "    x_col = X.shape[1]\n",
    "    \n",
    "    # Set the initial theta and other initial variables\n",
    "    theta = np.zeros((x_col, 1))\n",
    "    \n",
    "    start_i = 0\n",
    "    \n",
    "    # Create the loop\n",
    "    for i in range(start_i + 1, num_iter + 1):\n",
    "        # For each randomized-mini-batch partition\n",
    "        for j in range(0, len(df)):\n",
    "            X = df[j][0]\n",
    "            y = df[j][1]\n",
    "            \n",
    "            y_hat = np.dot(X, theta)\n",
    "            \n",
    "            # Break if overflow occurs\n",
    "            theta = theta - learning_rate * np.dot(X.T, y_hat - y)\n",
    "            \n",
    "            # FIXME: Break if NaN occurs\n",
    "            # if not (float('-inf') < float(temp[0]) < float('inf')): \n",
    "            #    return theta\n",
    "                \n",
    "            # theta =  temp\n",
    "            \n",
    "        \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6.2\n",
    "\n",
    "> Consider n-degree polynomials, φ(·) =  1 x x^2 · · · x^n . Download the dataset on the course webpage and work with ‘dataset1’. Run the code on the training data to compute θ for n ∈ {2, 3, 5}. Evaluate the regression error on both training and the test data. Report θ, training error and test error for both implementation (closed-form vs gradient descent). What is the effect of the size of the mini-batch on the speed and testing error of the solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.40148277]])"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = scipy.io.loadmat(\"/Users/bagustrihatmaja/Downloads/HW1_Data/dataset1.mat\")\n",
    "\n",
    "\n",
    "X_trn = df['X_trn']\n",
    "Y_trn = df['Y_trn']\n",
    "X_test = df['X_tst']\n",
    "Y_test = df['Y_tst']\n",
    "\n",
    "\n",
    "closed_function_regression(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.17254611]])"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_polinomial_array(element, n):\n",
    "    pol = np.empty([1, n+1])\n",
    "    # Debug\n",
    "    # print(pol)\n",
    "    for i in range(0, n+1):\n",
    "        # Debug\n",
    "        # print(\"Element: \\n\", element)\n",
    "        pol[0][i] = element ** i\n",
    "        \n",
    "    return pol[0]\n",
    "\n",
    "# Here we set the degree of polynomial        \n",
    "degree = 5\n",
    "# degree + 1 for 1's in the first column\n",
    "X_trn_new = np.ndarray((len(X_trn), degree + 1))\n",
    "\n",
    "# print(X_trn_new)\n",
    "\n",
    "i = 0\n",
    "X = np.array(X_trn)\n",
    "for x in X:\n",
    "    X_trn_new[i] = create_polinomial_array(x, degree)\n",
    "    i += 1\n",
    "        \n",
    "\n",
    "mini_gradient_descent(X_trn, Y_trn, 0.001, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysing the regression error and speed\n",
    "# Hyper-parameter are the alpha (learning rate), the batch size and the number of iterations\n",
    "def analyze(learning_rate, n_iteration, batch_size):\n",
    "    degrees = [2, 3, 5]\n",
    "    \n",
    "    # Time for performance\n",
    "    grad_desc_performance = []\n",
    "    \n",
    "    # For train data\n",
    "    error_closed_form_train = []\n",
    "    error_grad_desc_train = []\n",
    "    \n",
    "    # For test data\n",
    "    error_closed_form_test = []\n",
    "    error_grad_desc_test = []\n",
    "    \n",
    "    X = np.array(X_trn)\n",
    "    X_tst = np.array(X_test)\n",
    "    \n",
    "    for degree in degrees:\n",
    "        X_trn_new = np.ndarray((len(X_trn), degree + 1))\n",
    "        X_tst_new = np.ndarray((len(X_tst), degree + 1))\n",
    "        \n",
    "        i = 0\n",
    "        for x in X:\n",
    "            X_trn_new[i] = create_polinomial_array(x, degree)\n",
    "            i += 1\n",
    "        \n",
    "        i = 0\n",
    "        for x in X_tst:\n",
    "            X_tst_new[i] = create_polinomial_array(x, degree)\n",
    "            i += 1\n",
    "        \n",
    "        tetha_closed_form = closed_function_regression(X_trn_new, Y_trn)\n",
    "        t = time.process_time()\n",
    "        tetha_grad_desc = mini_gradient_descent(X_trn_new, Y_trn, learning_rate, n_iteration, batch_size)\n",
    "        elapsed_time = time.process_time() - t\n",
    "        print(\"Theta for degree {} done in: {}\\n\".format(degree, elapsed_time))\n",
    "        \n",
    "        \n",
    "        y_hat_closed_form_train = np.dot(X_trn_new, tetha_closed_form)\n",
    "        y_hat_grad_desc_train = np.dot(X_trn_new, tetha_grad_desc)\n",
    "        \n",
    "        y_hat_closed_form_test = np.dot(X_tst_new, tetha_closed_form)\n",
    "        y_hat_grad_desc_test = np.dot(X_tst_new, tetha_grad_desc)\n",
    "        \n",
    "        error_closed_form_train.append(np.sqrt(((Y_trn - y_hat_closed_form_train) ** 2).mean()))\n",
    "        error_grad_desc_train.append(np.sqrt(((Y_trn - y_hat_grad_desc_train) ** 2).mean()))\n",
    "        \n",
    "        error_closed_form_test.append(np.sqrt(((Y_test - y_hat_closed_form_test) ** 2).mean()))\n",
    "        error_grad_desc_test.append(np.sqrt(((Y_test - y_hat_grad_desc_test) ** 2).mean()))\n",
    "        \n",
    "    d = {\n",
    "        'degree': [2, 3, 5],\n",
    "        'close_form_error_train': error_closed_form_train,\n",
    "        'grad_desc_error_train': error_grad_desc_train,\n",
    "        'close_form_error_test': error_closed_form_test,\n",
    "        'grad_desc_error_test': error_grad_desc_test\n",
    "    }\n",
    "    errors = pd.DataFrame(data = d)\n",
    "    return errors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta for degree 2 done in: 0.007232999999999379\n\nTheta for degree 3 done in: 0.0033169999999955735\n\nTheta for degree 5 done in: 0.00168699999998978\n\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_form_error_test</th>\n",
       "      <th>close_form_error_train</th>\n",
       "      <th>degree</th>\n",
       "      <th>grad_desc_error_test</th>\n",
       "      <th>grad_desc_error_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.434831</td>\n",
       "      <td>4.974125</td>\n",
       "      <td>2</td>\n",
       "      <td>7.538616e+01</td>\n",
       "      <td>1.652118e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.336971</td>\n",
       "      <td>1.991950</td>\n",
       "      <td>3</td>\n",
       "      <td>1.865774e+01</td>\n",
       "      <td>1.167766e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.442782</td>\n",
       "      <td>1.986676</td>\n",
       "      <td>5</td>\n",
       "      <td>5.080623e+90</td>\n",
       "      <td>2.000555e+89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_form_error_test</th>\n",
       "      <th>close_form_error_train</th>\n",
       "      <th>degree</th>\n",
       "      <th>grad_desc_error_test</th>\n",
       "      <th>grad_desc_error_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.434831</td>\n",
       "      <td>4.974125</td>\n",
       "      <td>2</td>\n",
       "      <td>7.538616e+01</td>\n",
       "      <td>1.652118e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.336971</td>\n",
       "      <td>1.991950</td>\n",
       "      <td>3</td>\n",
       "      <td>1.865774e+01</td>\n",
       "      <td>1.167766e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.442782</td>\n",
       "      <td>1.986676</td>\n",
       "      <td>5</td>\n",
       "      <td>5.080623e+90</td>\n",
       "      <td>2.000555e+89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size 10\n",
    "result1 = analyze(0.00001, 10, 10)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta for degree 2 done in: 0.0021930000000054406\n\nTheta for degree 3 done in: 0.0027790000000038617\n\nTheta for degree 5 done in: 0.0026310000000080436\n\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_form_error_test</th>\n",
       "      <th>close_form_error_train</th>\n",
       "      <th>degree</th>\n",
       "      <th>grad_desc_error_test</th>\n",
       "      <th>grad_desc_error_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.434831</td>\n",
       "      <td>4.974125</td>\n",
       "      <td>2</td>\n",
       "      <td>7.064596e+01</td>\n",
       "      <td>1.862262e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.336971</td>\n",
       "      <td>1.991950</td>\n",
       "      <td>3</td>\n",
       "      <td>2.631678e+01</td>\n",
       "      <td>1.405648e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.442782</td>\n",
       "      <td>1.986676</td>\n",
       "      <td>5</td>\n",
       "      <td>6.622336e+46</td>\n",
       "      <td>2.415631e+45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_form_error_test</th>\n",
       "      <th>close_form_error_train</th>\n",
       "      <th>degree</th>\n",
       "      <th>grad_desc_error_test</th>\n",
       "      <th>grad_desc_error_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.434831</td>\n",
       "      <td>4.974125</td>\n",
       "      <td>2</td>\n",
       "      <td>7.064596e+01</td>\n",
       "      <td>1.862262e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.336971</td>\n",
       "      <td>1.991950</td>\n",
       "      <td>3</td>\n",
       "      <td>2.631678e+01</td>\n",
       "      <td>1.405648e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.442782</td>\n",
       "      <td>1.986676</td>\n",
       "      <td>5</td>\n",
       "      <td>6.622336e+46</td>\n",
       "      <td>2.415631e+45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size 20\n",
    "result1 = analyze(0.00001, 6, 20)\n",
    "result1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the hyperparameter of `number of iteration` is 10 and `learning rate` is 0.00001 and we split the data by 10, so we get 12 partition. We get smaller RMSE compared to the closed form for our training data.\n",
    "\n",
    "The error we get varies depends on our hyperparameters we mention above. In case of polinomial of 5, we get better result if we increase the batch size and adjust the number of iteration accordingly.\n",
    "\n",
    "We have known bug that if we set the learning rate or the number of iteration too high, we will overflow exception (known bugs are marked as `# FIXME` in this report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6.3\n",
    "\n",
    "> Download the dataset on the course webpage and work with ‘dataset2’. Write a code in Python that applies Ridge regression to the dataset to compute θ for a given λ. Implement two cases:\n",
    " 2\n",
    "using a closed-form solution and using a stochastic gradient descent method with mini-batches of size m. Use K-fold cross validation on the training dataset to obtain the best regularization λ and apply the optimal θ to compute the regression error on test samples. Report the optimal λ, θ, test and training set errors for K ∈ {2,10,N}, where N is the number of samples. In all cases try n ∈ {2, 3, 5}. How does the test error change as a function of λ and n?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression(object):\n",
    "    def __init__(self, lmbda=0.1):\n",
    "        self.lmbda = lmbda\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        C = X.T.dot(X) + self.lmbda * np.eye(X.shape[1])\n",
    "        self.w = np.linalg.inv(C).dot(X.T.dot(y))\n",
    "    \n",
    "    def set_params(self, lmbda=0.1):\n",
    "        self.lmbda = lmbda\n",
    "        return self\n",
    "        \n",
    "    def get_weight(self):\n",
    "        return self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Minimisation(object):\n",
    "    def __init__(self, X, y, model):\n",
    "        self.model = model\n",
    "        # Prepare the data\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "        \n",
    "    def closed_form(self):\n",
    "        self.model.fit(self.X, self.y)\n",
    "        return self.model.get_weight()\n",
    "    \n",
    "    def mini_batch_stochastic(self, batch_size):\n",
    "        y = np.array(y)\n",
    "    \n",
    "        # Randomize the data and split into samples\n",
    "        df = shuffle_data(X, y, batch_size)\n",
    "    \n",
    "        # Get the dimension\n",
    "        x_dim = X.shape[1]\n",
    "    \n",
    "        # Set the initial tetha and other initial variables\n",
    "        theta = np.zeros((x_dim, 1))\n",
    "    \n",
    "        start_i = 0\n",
    "    \n",
    "        # Create the loop\n",
    "        for i in range(start_i + 1, num_iter + 1):\n",
    "            # For each randomized-mini-batch partition\n",
    "            for j in range(0, len(df)):\n",
    "                X = df[j][0]\n",
    "                y = df[j][1]\n",
    "                \n",
    "                self.model.fit(self.X, self.y)\n",
    "                theta = theta - learning_rate * self.model.get_weight \n",
    "        \n",
    "        return theta\n",
    "        \n",
    "    def shuffle_data(self, batch_size):\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "    \n",
    "        random_indices = np.random.choice(len(X), len(y), replace=False)\n",
    "    \n",
    "        X_shuffled = X[random_indices,:]\n",
    "        y_shuffled = y[random_indices]\n",
    "        mini_batches = [(X_shuffled[i:i+batch_size,:], y_shuffled[i:i+batch_size]) for\n",
    "                   i in range(0, len(y), batch_size)]\n",
    "        return mini_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.70785672]]\n"
     ]
    }
   ],
   "source": [
    "df2 = scipy.io.loadmat(\"/Users/bagustrihatmaja/Downloads/HW1_Data/dataset2.mat\")\n",
    "X_trn = df2['X_trn']\n",
    "Y_trn = df2['Y_trn']\n",
    "\n",
    "ridge = RidgeRegression()\n",
    "m = Minimisation(X_trn, Y_trn, ridge)\n",
    "print(m.closed_form())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
